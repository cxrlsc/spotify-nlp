{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b58f196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ccal0507/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e86796",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770063fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lyrics.csv')\n",
    "# Removing any songs without lyrics \n",
    "df = df[~(pd.isna(df['lyrics']) | pd.isna(df['release date']))]\n",
    "df.head()\n",
    "\n",
    "# Defining a dataset with nonempty descriptions for *maybe* future use\n",
    "data = df.query(\"description != '?'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9662926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 373 entries, 0 to 384\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   artist        373 non-null    object\n",
      " 1   title         373 non-null    object\n",
      " 2   lyrics        373 non-null    object\n",
      " 3   description   373 non-null    object\n",
      " 4   release date  373 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 17.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Original data description \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222a73f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 313 entries, 0 to 384\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   artist        313 non-null    object\n",
      " 1   title         313 non-null    object\n",
      " 2   lyrics        313 non-null    object\n",
      " 3   description   313 non-null    object\n",
      " 4   release date  313 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 14.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Nonempty description data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a94951",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "\n",
    "### Cleaning `lyrics`, `artist`, and `title`  \n",
    "In this section we are removing any unecessary text found in the lyrics column. In addition, we are lowercasing all other textual columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9ff62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics(test_str):\n",
    "    \n",
    "    test_str = str(test_str)\n",
    "    # 0) Removing apostrophes for tokenization purposes\n",
    "    test_str = test_str.lower().replace(\"'\", \"\")\n",
    "    \n",
    "    # 1) Removing unecessary textual data \n",
    "    res = re.search(r'lyrics' , test_str)\n",
    "    emb_res = re.search(r'\\d*embed$', test_str)\n",
    "\n",
    "    test_str = test_str[res.end():emb_res.start()]\n",
    "\n",
    "    # 2) Removing any punctuation (except parantheses)\n",
    "    test_str = re.sub(r'[.,\\-?:!;]', '', test_str)\n",
    "\n",
    "    return test_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54bd3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lyrics'] = df['lyrics'].apply(clean_lyrics)\n",
    "df['artist'] = df['artist'].str.lower()\n",
    "df['title'] = df['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f55f88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>description</th>\n",
       "      <th>release date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>hit the road jack</td>\n",
       "      <td>\\nhit the road jack and doncha come back\\nno m...</td>\n",
       "      <td>This tongue and cheek verbal duel of a couple ...</td>\n",
       "      <td>August 1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>georgia on my mind</td>\n",
       "      <td>\\ngeorgia\\ngeorgia\\nthe whole day through\\n(th...</td>\n",
       "      <td>Written by Hoagy Carmichael and Stuart Gorrell...</td>\n",
       "      <td>September 1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>i’ve got a woman</td>\n",
       "      <td>\\nwell\\n\\ni got a woman way over town\\nthats g...</td>\n",
       "      <td>Ray Charles released “I’ve Got a Woman” as a s...</td>\n",
       "      <td>December 1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>i can’t stop loving you</td>\n",
       "      <td>\\n(i cant stop loving you)\\nive made up my min...</td>\n",
       "      <td>?</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ken nordine</td>\n",
       "      <td>yellow</td>\n",
       "      <td>in the beginning\\noh long before that\\nwhen li...</td>\n",
       "      <td>?</td>\n",
       "      <td>January 1, 1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>raveena</td>\n",
       "      <td>temptation</td>\n",
       "      <td>ahahah\\nahahah\\n\\nmiss temptation i dont think...</td>\n",
       "      <td>In “Temptation”, Raveena opens up about her bi...</td>\n",
       "      <td>October 23, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>the notorious b.i.g.</td>\n",
       "      <td>juicy</td>\n",
       "      <td>\\n(\"fuck all you hoes\" get a grip motherfucker...</td>\n",
       "      <td>“Juicy” is the first single from Big’s debut a...</td>\n",
       "      <td>August 9, 1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>the notorious b.i.g.</td>\n",
       "      <td>big poppa</td>\n",
       "      <td>\\nuh uh check it out (yeah) uh\\njunior mafia u...</td>\n",
       "      <td>“Big Poppa” was The Notorious B.I.G.’s first t...</td>\n",
       "      <td>February 20, 1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>the notorious b.i.g.</td>\n",
       "      <td>suicidal thoughts</td>\n",
       "      <td>\\nhello\\naw shit nigga the fuck time is it man...</td>\n",
       "      <td>In this final track off of The Notorious B.I.G...</td>\n",
       "      <td>September 13, 1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>the notorious b.i.g.</td>\n",
       "      <td>hypnotize</td>\n",
       "      <td>\\nuh uh (uh come on)\\n\\nha sicker than your av...</td>\n",
       "      <td>Biggie’s first number one hit “Hypnotize” was ...</td>\n",
       "      <td>March 1, 1997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   artist                    title  \\\n",
       "0             ray charles        hit the road jack   \n",
       "1             ray charles       georgia on my mind   \n",
       "2             ray charles         i’ve got a woman   \n",
       "3             ray charles  i can’t stop loving you   \n",
       "4             ken nordine                   yellow   \n",
       "..                    ...                      ...   \n",
       "380               raveena               temptation   \n",
       "381  the notorious b.i.g.                    juicy   \n",
       "382  the notorious b.i.g.                big poppa   \n",
       "383  the notorious b.i.g.        suicidal thoughts   \n",
       "384  the notorious b.i.g.                hypnotize   \n",
       "\n",
       "                                                lyrics  \\\n",
       "0    \\nhit the road jack and doncha come back\\nno m...   \n",
       "1    \\ngeorgia\\ngeorgia\\nthe whole day through\\n(th...   \n",
       "2    \\nwell\\n\\ni got a woman way over town\\nthats g...   \n",
       "3    \\n(i cant stop loving you)\\nive made up my min...   \n",
       "4    in the beginning\\noh long before that\\nwhen li...   \n",
       "..                                                 ...   \n",
       "380  ahahah\\nahahah\\n\\nmiss temptation i dont think...   \n",
       "381  \\n(\"fuck all you hoes\" get a grip motherfucker...   \n",
       "382  \\nuh uh check it out (yeah) uh\\njunior mafia u...   \n",
       "383  \\nhello\\naw shit nigga the fuck time is it man...   \n",
       "384  \\nuh uh (uh come on)\\n\\nha sicker than your av...   \n",
       "\n",
       "                                           description        release date  \n",
       "0    This tongue and cheek verbal duel of a couple ...         August 1961  \n",
       "1    Written by Hoagy Carmichael and Stuart Gorrell...      September 1960  \n",
       "2    Ray Charles released “I’ve Got a Woman” as a s...       December 1954  \n",
       "3                                                    ?                1962  \n",
       "4                                                    ?     January 1, 1966  \n",
       "..                                                 ...                 ...  \n",
       "380  In “Temptation”, Raveena opens up about her bi...    October 23, 2018  \n",
       "381  “Juicy” is the first single from Big’s debut a...      August 9, 1994  \n",
       "382  “Big Poppa” was The Notorious B.I.G.’s first t...   February 20, 1995  \n",
       "383  In this final track off of The Notorious B.I.G...  September 13, 1994  \n",
       "384  Biggie’s first number one hit “Hypnotize” was ...       March 1, 1997  \n",
       "\n",
       "[373 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c509f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>description</th>\n",
       "      <th>release date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>hit the road jack</td>\n",
       "      <td>\\nhit the road jack and doncha come back\\nno m...</td>\n",
       "      <td>This tongue and cheek verbal duel of a couple ...</td>\n",
       "      <td>August 1961</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>georgia on my mind</td>\n",
       "      <td>\\ngeorgia\\ngeorgia\\nthe whole day through\\n(th...</td>\n",
       "      <td>Written by Hoagy Carmichael and Stuart Gorrell...</td>\n",
       "      <td>September 1960</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>i’ve got a woman</td>\n",
       "      <td>\\nwell\\n\\ni got a woman way over town\\nthats g...</td>\n",
       "      <td>Ray Charles released “I’ve Got a Woman” as a s...</td>\n",
       "      <td>December 1954</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>i can’t stop loving you</td>\n",
       "      <td>\\n(i cant stop loving you)\\nive made up my min...</td>\n",
       "      <td>?</td>\n",
       "      <td>1962</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ken nordine</td>\n",
       "      <td>yellow</td>\n",
       "      <td>in the beginning\\noh long before that\\nwhen li...</td>\n",
       "      <td>?</td>\n",
       "      <td>January 1, 1966</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>raveena</td>\n",
       "      <td>temptation</td>\n",
       "      <td>ahahah\\nahahah\\n\\nmiss temptation i dont think...</td>\n",
       "      <td>In “Temptation”, Raveena opens up about her bi...</td>\n",
       "      <td>October 23, 2018</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>the notorious b.i.g.</td>\n",
       "      <td>juicy</td>\n",
       "      <td>\\n(\"fuck all you hoes\" get a grip motherfucker...</td>\n",
       "      <td>“Juicy” is the first single from Big’s debut a...</td>\n",
       "      <td>August 9, 1994</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>the notorious b.i.g.</td>\n",
       "      <td>big poppa</td>\n",
       "      <td>\\nuh uh check it out (yeah) uh\\njunior mafia u...</td>\n",
       "      <td>“Big Poppa” was The Notorious B.I.G.’s first t...</td>\n",
       "      <td>February 20, 1995</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>the notorious b.i.g.</td>\n",
       "      <td>suicidal thoughts</td>\n",
       "      <td>\\nhello\\naw shit nigga the fuck time is it man...</td>\n",
       "      <td>In this final track off of The Notorious B.I.G...</td>\n",
       "      <td>September 13, 1994</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>the notorious b.i.g.</td>\n",
       "      <td>hypnotize</td>\n",
       "      <td>\\nuh uh (uh come on)\\n\\nha sicker than your av...</td>\n",
       "      <td>Biggie’s first number one hit “Hypnotize” was ...</td>\n",
       "      <td>March 1, 1997</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   artist                    title  \\\n",
       "0             ray charles        hit the road jack   \n",
       "1             ray charles       georgia on my mind   \n",
       "2             ray charles         i’ve got a woman   \n",
       "3             ray charles  i can’t stop loving you   \n",
       "4             ken nordine                   yellow   \n",
       "..                    ...                      ...   \n",
       "380               raveena               temptation   \n",
       "381  the notorious b.i.g.                    juicy   \n",
       "382  the notorious b.i.g.                big poppa   \n",
       "383  the notorious b.i.g.        suicidal thoughts   \n",
       "384  the notorious b.i.g.                hypnotize   \n",
       "\n",
       "                                                lyrics  \\\n",
       "0    \\nhit the road jack and doncha come back\\nno m...   \n",
       "1    \\ngeorgia\\ngeorgia\\nthe whole day through\\n(th...   \n",
       "2    \\nwell\\n\\ni got a woman way over town\\nthats g...   \n",
       "3    \\n(i cant stop loving you)\\nive made up my min...   \n",
       "4    in the beginning\\noh long before that\\nwhen li...   \n",
       "..                                                 ...   \n",
       "380  ahahah\\nahahah\\n\\nmiss temptation i dont think...   \n",
       "381  \\n(\"fuck all you hoes\" get a grip motherfucker...   \n",
       "382  \\nuh uh check it out (yeah) uh\\njunior mafia u...   \n",
       "383  \\nhello\\naw shit nigga the fuck time is it man...   \n",
       "384  \\nuh uh (uh come on)\\n\\nha sicker than your av...   \n",
       "\n",
       "                                           description        release date  \\\n",
       "0    This tongue and cheek verbal duel of a couple ...         August 1961   \n",
       "1    Written by Hoagy Carmichael and Stuart Gorrell...      September 1960   \n",
       "2    Ray Charles released “I’ve Got a Woman” as a s...       December 1954   \n",
       "3                                                    ?                1962   \n",
       "4                                                    ?     January 1, 1966   \n",
       "..                                                 ...                 ...   \n",
       "380  In “Temptation”, Raveena opens up about her bi...    October 23, 2018   \n",
       "381  “Juicy” is the first single from Big’s debut a...      August 9, 1994   \n",
       "382  “Big Poppa” was The Notorious B.I.G.’s first t...   February 20, 1995   \n",
       "383  In this final track off of The Notorious B.I.G...  September 13, 1994   \n",
       "384  Biggie’s first number one hit “Hypnotize” was ...       March 1, 1997   \n",
       "\n",
       "     year  \n",
       "0    1961  \n",
       "1    1960  \n",
       "2    1954  \n",
       "3    1962  \n",
       "4    1966  \n",
       "..    ...  \n",
       "380  2018  \n",
       "381  1994  \n",
       "382  1995  \n",
       "383  1994  \n",
       "384  1997  \n",
       "\n",
       "[373 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'] = pd.to_datetime(df['release date']).dt.year\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c427e4",
   "metadata": {},
   "source": [
    "### Building our Feature Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46c4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb9014a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_df = df[df['artist'] == 'the notorious b.i.g.']\n",
    "corpus = list(curr_df['lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65651c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14f2c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_sequences, total_words = get_sequence_of_tokens(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e3367a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "816"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e93eac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = np_utils.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dcd5fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad34fc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d675c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(100))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_sequence_len, total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f314ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "88/88 - 62s - loss: 6.2524\n",
      "Epoch 2/10\n",
      "88/88 - 59s - loss: 5.8697\n",
      "Epoch 3/10\n",
      "88/88 - 60s - loss: 5.8151\n",
      "Epoch 4/10\n",
      "88/88 - 61s - loss: 5.7586\n",
      "Epoch 5/10\n",
      "88/88 - 60s - loss: 5.6797\n",
      "Epoch 6/10\n",
      "88/88 - 60s - loss: 5.6311\n",
      "Epoch 7/10\n",
      "88/88 - 61s - loss: 5.4989\n",
      "Epoch 8/10\n",
      "88/88 - 62s - loss: 5.4054\n",
      "Epoch 9/10\n",
      "88/88 - 61s - loss: 5.3115\n",
      "Epoch 10/10\n",
      "88/88 - 59s - loss: 5.2034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f21c83e5100>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48664130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        #predicted = model.predict_classes(token_list, verbose=0)\n",
    "        \n",
    "        predict_x=model.predict(token_list) \n",
    "        classes_x=np.argmax(predict_x,axis=1)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == classes_x:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word        \n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b63d6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Want I The Fuckin To My Fuckin To To My Back To My Back To My Fuckin To My Back To\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"You want\", 20, model, max_sequence_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e398cf",
   "metadata": {},
   "source": [
    "## Text Summarization Baseline Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8c0d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.2.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "     |████████████████████████████████| 6.2 MB 6.3 MB/s            \n",
      "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp38-cp38-manylinux2014_x86_64.whl (13.7 MB)\n",
      "     |████████████████████████████████| 13.7 MB 48.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: setuptools in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy) (52.0.0.post20210125)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     |████████████████████████████████| 181 kB 54.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy) (1.22.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy) (4.63.0)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (663 kB)\n",
      "     |████████████████████████████████| 663 kB 4.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy) (2.27.1)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy) (21.3)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "     |████████████████████████████████| 9.9 MB 29.1 MB/s            \n",
      "\u001b[?25hCollecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
      "     |████████████████████████████████| 454 kB 55.4 MB/s            \n",
      "\u001b[?25hCollecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 2.2 MB/s             \n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "     |████████████████████████████████| 130 kB 25.3 MB/s            \n",
      "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (3.0.7)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "     |████████████████████████████████| 58 kB 9.0 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.9.0\n",
      "    Uninstalling pydantic-1.9.0:\n",
      "      Successfully uninstalled pydantic-1.9.0\n",
      "Successfully installed blis-0.7.7 catalogue-2.0.7 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.6 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 smart-open-5.2.1 spacy-3.2.3 spacy-legacy-3.0.9 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.15 typer-0.4.0 wasabi-0.9.0\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/ccal0507/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "2022-03-24 04:47:01.827835: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-24 04:47:01.828039: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "     |████████████████████████████████| 13.9 MB 9.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from en-core-web-sm==3.2.0) (3.2.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: jinja2 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: setuptools in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.63.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.22.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.2.0\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/ccal0507/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "befad7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import spacy.lang.en.stop_words as STOP_WORDS\n",
    "from string import punctuation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54285c79",
   "metadata": {},
   "source": [
    "Will first attempt to summarize one song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a57e03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhello\\naw shit nigga the fuck time is it man\\noh god damn\\nnigga do you know what time it is\\naw shit what the fucks goin on\\nyou aight\\nah nigga what the fuck is wrong with you\\n\\nwhen i die fuck it i wanna go to hell\\ncause im a piece of shit it aint hard to fuckin tell (what you talkin bout man)\\nit dont make sense goin to heaven with the goodiegoodies\\ndressed in white i like black timbs and black hoodies (aw man)\\ngodll probably have me on some real strict shit\\nno sleepin all day no gettin my dick licked\\nhangin with the goodiegoodies loungin in paradise\\nfuck that shit i wanna tote guns and shoot dice (you talkin some crazy shit now nigga)\\nall my life i been considered as the worst\\nlyin to my mother even stealin out her purse (ah)\\ncrime after crime from drugs to extortion\\ni know my mother wish she got a fuckin abortion\\nshe dont even love me like she did when i was younger (yo get a hold of yourself nigga)\\nsuckin on her chest just to stop my fuckin hunger\\ni wonder if i died would tears come to her eyes\\nforgive me for my disrespect forgive me for my lies (youre buggin b)\\nmy baby mothers eight months her little sisters two\\nwhos to blame for both of them (nah nigga not you)\\ni swear to god i want to just slit my wrists and end this bullshit\\nthrow the magnum to my head threaten to pull shit (nigga what the fuck)\\nand squeeze until the beds completely red (its too late for this shit man)\\nim glad im dead a worthless fuckin buddha head\\nthe stress is buildin up i cant— i cant believe (ayo im on my way over there man)\\nsuicides on my fuckin mind i wanna leave\\ni swear to god i feel like death is fuckin callin me\\nbut nah you wouldnt understand\\nnigga talk to me please man\\nyou see its kinda like the crack did to pookie in new jack\\nexcept when i cross over there aint no comin back (ayo ayo man im out)\\nshould i die on the train track like ramo in beat street (ima call you when i get in the car)\\npeople at the funeral frontin like they miss me (ayo where your girl at man)\\nmy baby mama kiss me but she glad im gone (yo put your girl on the phone nigga)\\nshe know me and her sister had somethin goin on\\ni reach my peak i cant speak (ayo you listenin to me motherfucker)\\ncall my nigga chic tell him that my will is weak (ayo cmon nigga)\\nim sick of niggas lyin (cut that) im sick of bitches hawkin (ayo)\\nmatter of fact im sick of talkin (nigga yo yo big ayo chill)\\n*gunshot*\\nayo big ayo big\\nplease hang up and try your call again\\nplease hang up— is a recording'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['lyrics'][383]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91e40ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(STOP_WORDS.STOP_WORDS)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fc9c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "265741b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'hello', '\\n', 'aw', 'shit', 'nigga', 'the', 'fuck', 'time', 'is', 'it', 'man', '\\n', 'oh', 'god', 'damn', '\\n', 'nigga', 'do', 'you', 'know', 'what', 'time', 'it', 'is', '\\n', 'aw', 'shit', 'what', 'the', 'fucks', 'goin', 'on', '\\n', 'you', 'aight', '\\n', 'ah', 'nigga', 'what', 'the', 'fuck', 'is', 'wrong', 'with', 'you', '\\n\\n', 'when', 'i', 'die', 'fuck', 'it', 'i', 'wanna', 'go', 'to', 'hell', '\\n', 'cause', 'i', 'm', 'a', 'piece', 'of', 'shit', 'it', 'ai', 'nt', 'hard', 'to', 'fuckin', 'tell', '(', 'what', 'you', 'talkin', 'bout', 'man', ')', '\\n', 'it', 'do', 'nt', 'make', 'sense', 'goin', 'to', 'heaven', 'with', 'the', 'goodiegoodies', '\\n', 'dressed', 'in', 'white', 'i', 'like', 'black', 'timbs', 'and', 'black', 'hoodies', '(', 'aw', 'man', ')', '\\n', 'godll', 'probably', 'have', 'me', 'on', 'some', 'real', 'strict', 'shit', '\\n', 'no', 'sleepin', 'all', 'day', 'no', 'gettin', 'my', 'dick', 'licked', '\\n', 'hangin', 'with', 'the', 'goodiegoodies', 'loungin', 'in', 'paradise', '\\n', 'fuck', 'that', 'shit', 'i', 'wanna', 'tote', 'guns', 'and', 'shoot', 'dice', '(', 'you', 'talkin', 'some', 'crazy', 'shit', 'now', 'nigga', ')', '\\n', 'all', 'my', 'life', 'i', 'been', 'considered', 'as', 'the', 'worst', '\\n', 'lyin', 'to', 'my', 'mother', 'even', 'stealin', 'out', 'her', 'purse', '(', 'ah', ')', '\\n', 'crime', 'after', 'crime', 'from', 'drugs', 'to', 'extortion', '\\n', 'i', 'know', 'my', 'mother', 'wish', 'she', 'got', 'a', 'fuckin', 'abortion', '\\n', 'she', 'do', 'nt', 'even', 'love', 'me', 'like', 'she', 'did', 'when', 'i', 'was', 'younger', '(', 'yo', 'get', 'a', 'hold', 'of', 'yourself', 'nigga', ')', '\\n', 'suckin', 'on', 'her', 'chest', 'just', 'to', 'stop', 'my', 'fuckin', 'hunger', '\\n', 'i', 'wonder', 'if', 'i', 'died', 'would', 'tears', 'come', 'to', 'her', 'eyes', '\\n', 'forgive', 'me', 'for', 'my', 'disrespect', 'forgive', 'me', 'for', 'my', 'lies', '(', 'you', 're', 'buggin', 'b', ')', '\\n', 'my', 'baby', 'mothers', 'eight', 'months', 'her', 'little', 'sisters', 'two', '\\n', 'who', 's', 'to', 'blame', 'for', 'both', 'of', 'them', '(', 'nah', 'nigga', 'not', 'you', ')', '\\n', 'i', 'swear', 'to', 'god', 'i', 'want', 'to', 'just', 'slit', 'my', 'wrists', 'and', 'end', 'this', 'bullshit', '\\n', 'throw', 'the', 'magnum', 'to', 'my', 'head', 'threaten', 'to', 'pull', 'shit', '(', 'nigga', 'what', 'the', 'fuck', ')', '\\n', 'and', 'squeeze', 'until', 'the', 'beds', 'completely', 'red', '(', 'its', 'too', 'late', 'for', 'this', 'shit', 'man', ')', '\\n', 'i', 'm', 'glad', 'i', 'm', 'dead', 'a', 'worthless', 'fuckin', 'buddha', 'head', '\\n', 'the', 'stress', 'is', 'buildin', 'up', 'i', 'ca', 'nt', '—', 'i', 'ca', 'nt', 'believe', '(', 'ayo', 'i', 'm', 'on', 'my', 'way', 'over', 'there', 'man', ')', '\\n', 'suicides', 'on', 'my', 'fuckin', 'mind', 'i', 'wanna', 'leave', '\\n', 'i', 'swear', 'to', 'god', 'i', 'feel', 'like', 'death', 'is', 'fuckin', 'callin', 'me', '\\n', 'but', 'nah', 'you', 'would', 'nt', 'understand', '\\n', 'nigga', 'talk', 'to', 'me', 'please', 'man', '\\n', 'you', 'see', 'its', 'kinda', 'like', 'the', 'crack', 'did', 'to', 'pookie', 'in', 'new', 'jack', '\\n', 'except', 'when', 'i', 'cross', 'over', 'there', 'ai', 'nt', 'no', 'comin', 'back', '(', 'ayo', 'ayo', 'man', 'i', 'm', 'out', ')', '\\n', 'should', 'i', 'die', 'on', 'the', 'train', 'track', 'like', 'ramo', 'in', 'beat', 'street', '(', 'i', 'm', 'a', 'call', 'you', 'when', 'i', 'get', 'in', 'the', 'car', ')', '\\n', 'people', 'at', 'the', 'funeral', 'frontin', 'like', 'they', 'miss', 'me', '(', 'ayo', 'where', 'your', 'girl', 'at', 'man', ')', '\\n', 'my', 'baby', 'mama', 'kiss', 'me', 'but', 'she', 'glad', 'i', 'm', 'gone', '(', 'yo', 'put', 'your', 'girl', 'on', 'the', 'phone', 'nigga', ')', '\\n', 'she', 'know', 'me', 'and', 'her', 'sister', 'had', 'somethin', 'goin', 'on', '\\n', 'i', 'reach', 'my', 'peak', 'i', 'ca', 'nt', 'speak', '(', 'ayo', 'you', 'listenin', 'to', 'me', 'motherfucker', ')', '\\n', 'call', 'my', 'nigga', 'chic', 'tell', 'him', 'that', 'my', 'will', 'is', 'weak', '(', 'ayo', 'cmon', 'nigga', ')', '\\n', 'i', 'm', 'sick', 'of', 'niggas', 'lyin', '(', 'cut', 'that', ')', 'i', 'm', 'sick', 'of', 'bitches', 'hawkin', '(', 'ayo', ')', '\\n', 'matter', 'of', 'fact', 'i', 'm', 'sick', 'of', 'talkin', '(', 'nigga', 'yo', 'yo', 'big', 'ayo', 'chill', ')', '\\n', '*', 'gunshot', '*', '\\n', 'ayo', 'big', 'ayo', 'big', '\\n', 'please', 'hang', 'up', 'and', 'try', 'your', 'call', 'again', '\\n', 'please', 'hang', 'up', '—', 'is', 'a', 'recording']\n"
     ]
    }
   ],
   "source": [
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8873637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4a103f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding how many times each token appears in the song \n",
    "\n",
    "word_frequencies = {}\n",
    "\n",
    "for word in doc:\n",
    "    if word.text not in word_frequencies.keys():\n",
    "        word_frequencies[word.text] = 1\n",
    "    else:\n",
    "        word_frequencies[word.text] += 1\n",
    "\n",
    "# Ideas: Deal with \\n and () differently --> they mean something else in lyrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d309a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 47,\n",
       " 'hello': 1,\n",
       " 'aw': 3,\n",
       " 'shit': 8,\n",
       " 'nigga': 12,\n",
       " 'the': 15,\n",
       " 'fuck': 5,\n",
       " 'time': 2,\n",
       " 'is': 7,\n",
       " 'it': 5,\n",
       " 'man': 8,\n",
       " 'oh': 1,\n",
       " 'god': 3,\n",
       " 'damn': 1,\n",
       " 'do': 3,\n",
       " 'you': 11,\n",
       " 'know': 3,\n",
       " 'what': 5,\n",
       " 'fucks': 1,\n",
       " 'goin': 3,\n",
       " 'on': 8,\n",
       " 'aight': 1,\n",
       " 'ah': 2,\n",
       " 'wrong': 1,\n",
       " 'with': 3,\n",
       " '\\n\\n': 1,\n",
       " 'when': 4,\n",
       " 'i': 31,\n",
       " 'die': 2,\n",
       " 'wanna': 3,\n",
       " 'go': 1,\n",
       " 'to': 16,\n",
       " 'hell': 1,\n",
       " 'cause': 1,\n",
       " 'm': 10,\n",
       " 'a': 6,\n",
       " 'piece': 1,\n",
       " 'of': 7,\n",
       " 'ai': 2,\n",
       " 'nt': 8,\n",
       " 'hard': 1,\n",
       " 'fuckin': 6,\n",
       " 'tell': 2,\n",
       " '(': 19,\n",
       " 'talkin': 3,\n",
       " 'bout': 1,\n",
       " ')': 19,\n",
       " 'make': 1,\n",
       " 'sense': 1,\n",
       " 'heaven': 1,\n",
       " 'goodiegoodies': 2,\n",
       " 'dressed': 1,\n",
       " 'in': 5,\n",
       " 'white': 1,\n",
       " 'like': 6,\n",
       " 'black': 2,\n",
       " 'timbs': 1,\n",
       " 'and': 6,\n",
       " 'hoodies': 1,\n",
       " 'godll': 1,\n",
       " 'probably': 1,\n",
       " 'have': 1,\n",
       " 'me': 10,\n",
       " 'some': 2,\n",
       " 'real': 1,\n",
       " 'strict': 1,\n",
       " 'no': 3,\n",
       " 'sleepin': 1,\n",
       " 'all': 2,\n",
       " 'day': 1,\n",
       " 'gettin': 1,\n",
       " 'my': 16,\n",
       " 'dick': 1,\n",
       " 'licked': 1,\n",
       " 'hangin': 1,\n",
       " 'loungin': 1,\n",
       " 'paradise': 1,\n",
       " 'that': 3,\n",
       " 'tote': 1,\n",
       " 'guns': 1,\n",
       " 'shoot': 1,\n",
       " 'dice': 1,\n",
       " 'crazy': 1,\n",
       " 'now': 1,\n",
       " 'life': 1,\n",
       " 'been': 1,\n",
       " 'considered': 1,\n",
       " 'as': 1,\n",
       " 'worst': 1,\n",
       " 'lyin': 2,\n",
       " 'mother': 2,\n",
       " 'even': 2,\n",
       " 'stealin': 1,\n",
       " 'out': 2,\n",
       " 'her': 5,\n",
       " 'purse': 1,\n",
       " 'crime': 2,\n",
       " 'after': 1,\n",
       " 'from': 1,\n",
       " 'drugs': 1,\n",
       " 'extortion': 1,\n",
       " 'wish': 1,\n",
       " 'she': 5,\n",
       " 'got': 1,\n",
       " 'abortion': 1,\n",
       " 'love': 1,\n",
       " 'did': 2,\n",
       " 'was': 1,\n",
       " 'younger': 1,\n",
       " 'yo': 4,\n",
       " 'get': 2,\n",
       " 'hold': 1,\n",
       " 'yourself': 1,\n",
       " 'suckin': 1,\n",
       " 'chest': 1,\n",
       " 'just': 2,\n",
       " 'stop': 1,\n",
       " 'hunger': 1,\n",
       " 'wonder': 1,\n",
       " 'if': 1,\n",
       " 'died': 1,\n",
       " 'would': 2,\n",
       " 'tears': 1,\n",
       " 'come': 1,\n",
       " 'eyes': 1,\n",
       " 'forgive': 2,\n",
       " 'for': 4,\n",
       " 'disrespect': 1,\n",
       " 'lies': 1,\n",
       " 're': 1,\n",
       " 'buggin': 1,\n",
       " 'b': 1,\n",
       " 'baby': 2,\n",
       " 'mothers': 1,\n",
       " 'eight': 1,\n",
       " 'months': 1,\n",
       " 'little': 1,\n",
       " 'sisters': 1,\n",
       " 'two': 1,\n",
       " 'who': 1,\n",
       " 's': 1,\n",
       " 'blame': 1,\n",
       " 'both': 1,\n",
       " 'them': 1,\n",
       " 'nah': 2,\n",
       " 'not': 1,\n",
       " 'swear': 2,\n",
       " 'want': 1,\n",
       " 'slit': 1,\n",
       " 'wrists': 1,\n",
       " 'end': 1,\n",
       " 'this': 2,\n",
       " 'bullshit': 1,\n",
       " 'throw': 1,\n",
       " 'magnum': 1,\n",
       " 'head': 2,\n",
       " 'threaten': 1,\n",
       " 'pull': 1,\n",
       " 'squeeze': 1,\n",
       " 'until': 1,\n",
       " 'beds': 1,\n",
       " 'completely': 1,\n",
       " 'red': 1,\n",
       " 'its': 2,\n",
       " 'too': 1,\n",
       " 'late': 1,\n",
       " 'glad': 2,\n",
       " 'dead': 1,\n",
       " 'worthless': 1,\n",
       " 'buddha': 1,\n",
       " 'stress': 1,\n",
       " 'buildin': 1,\n",
       " 'up': 3,\n",
       " 'ca': 3,\n",
       " '—': 2,\n",
       " 'believe': 1,\n",
       " 'ayo': 10,\n",
       " 'way': 1,\n",
       " 'over': 2,\n",
       " 'there': 2,\n",
       " 'suicides': 1,\n",
       " 'mind': 1,\n",
       " 'leave': 1,\n",
       " 'feel': 1,\n",
       " 'death': 1,\n",
       " 'callin': 1,\n",
       " 'but': 2,\n",
       " 'understand': 1,\n",
       " 'talk': 1,\n",
       " 'please': 3,\n",
       " 'see': 1,\n",
       " 'kinda': 1,\n",
       " 'crack': 1,\n",
       " 'pookie': 1,\n",
       " 'new': 1,\n",
       " 'jack': 1,\n",
       " 'except': 1,\n",
       " 'cross': 1,\n",
       " 'comin': 1,\n",
       " 'back': 1,\n",
       " 'should': 1,\n",
       " 'train': 1,\n",
       " 'track': 1,\n",
       " 'ramo': 1,\n",
       " 'beat': 1,\n",
       " 'street': 1,\n",
       " 'call': 3,\n",
       " 'car': 1,\n",
       " 'people': 1,\n",
       " 'at': 2,\n",
       " 'funeral': 1,\n",
       " 'frontin': 1,\n",
       " 'they': 1,\n",
       " 'miss': 1,\n",
       " 'where': 1,\n",
       " 'your': 3,\n",
       " 'girl': 2,\n",
       " 'mama': 1,\n",
       " 'kiss': 1,\n",
       " 'gone': 1,\n",
       " 'put': 1,\n",
       " 'phone': 1,\n",
       " 'sister': 1,\n",
       " 'had': 1,\n",
       " 'somethin': 1,\n",
       " 'reach': 1,\n",
       " 'peak': 1,\n",
       " 'speak': 1,\n",
       " 'listenin': 1,\n",
       " 'motherfucker': 1,\n",
       " 'chic': 1,\n",
       " 'him': 1,\n",
       " 'will': 1,\n",
       " 'weak': 1,\n",
       " 'cmon': 1,\n",
       " 'sick': 3,\n",
       " 'niggas': 1,\n",
       " 'cut': 1,\n",
       " 'bitches': 1,\n",
       " 'hawkin': 1,\n",
       " 'matter': 1,\n",
       " 'fact': 1,\n",
       " 'big': 3,\n",
       " 'chill': 1,\n",
       " '*': 2,\n",
       " 'gunshot': 1,\n",
       " 'hang': 2,\n",
       " 'try': 1,\n",
       " 'again': 1,\n",
       " 'recording': 1}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f1868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd07718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4ce1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c288d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d32466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d565085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
