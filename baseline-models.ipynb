{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae2d0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow==2.6.2\n",
      "tensorflow-estimator==2.6.0\n",
      "sentencepiece==0.1.96\n",
      "transformers==4.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep tensorflow\n",
    "!pip freeze | grep sentencepiece\n",
    "!pip freeze | grep transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e006d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c79b499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel, T5Tokenizer, TFT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52329b61",
   "metadata": {},
   "source": [
    "# T5<a id=\"T5\" />\n",
    "\n",
    "\n",
    "Let us now lay the foundations for another useful model: **T5**. \n",
    "\n",
    "T5 is a pre-trained transformer-based text-to-text model introduced by C. Raffel et al in  [\"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\"](https://arxiv.org/pdf/1910.10683.pdf) , that is also available from Huggingface.  The idea is to view/rephrase tasks as 'text-to-text' problems:   \n",
    "\n",
    "T5 has performed very well on a variety of tasks.\n",
    "\n",
    "In this spirit, let us approach the NER classification discussed above in a completely different may: **as a translation problem**. This may certainly lead to less good results than the BERT model, as phrasing it as a translation problem is not very natural. But it is instructive nevertheless.\n",
    "\n",
    "(**Note:** this is pretty cutting-edge as there is very little information available on fine-tuning of T5 with TensorFlow/Keras. So this notebook should be viewed as work in progress, and mistakes may be present.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e20a164",
   "metadata": {},
   "source": [
    "T5 is available in various sizes. Here, we use the small size with about 60m parameters.\n",
    "\n",
    "### T5 as a Black Box\n",
    "\n",
    "Let us first play with Huggingface's T5 model. We start with the T5ForConditionalGeneration model imported above to verify some pre-training claims. This model uses a source sentence AND the task as an input and then generates the output token by token.\n",
    "\n",
    "Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe5e284f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "t5_model = 't5-small'\n",
    "\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(t5_model)\n",
    "t5 = TFT5ForConditionalGeneration.from_pretrained(t5_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "123f46c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>description</th>\n",
       "      <th>release date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>hit the road jack</td>\n",
       "      <td>\\nhit the road jack and doncha come back\\nno m...</td>\n",
       "      <td>This tongue and cheek verbal duel of a couple ...</td>\n",
       "      <td>August 1961</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>georgia on my mind</td>\n",
       "      <td>\\ngeorgia\\ngeorgia\\nthe whole day through\\n(th...</td>\n",
       "      <td>Written by Hoagy Carmichael and Stuart Gorrell...</td>\n",
       "      <td>September 1960</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist               title  \\\n",
       "0  ray charles   hit the road jack   \n",
       "1  ray charles  georgia on my mind   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  \\nhit the road jack and doncha come back\\nno m...   \n",
       "1  \\ngeorgia\\ngeorgia\\nthe whole day through\\n(th...   \n",
       "\n",
       "                                         description    release date  year  \n",
       "0  This tongue and cheek verbal duel of a couple ...     August 1961  1961  \n",
       "1  Written by Hoagy Carmichael and Stuart Gorrell...  September 1960  1960  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_lyrics.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fd31575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>description</th>\n",
       "      <th>release date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189</td>\n",
       "      <td>the beatles</td>\n",
       "      <td>let it be</td>\n",
       "      <td>\\nwhen i find myself in times of trouble mothe...</td>\n",
       "      <td>One of The Beatles' many iconic ballads, writt...</td>\n",
       "      <td>May 8, 1970</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>the beatles</td>\n",
       "      <td>yesterday</td>\n",
       "      <td>\\nyesterday\\nall my troubles seemed so far awa...</td>\n",
       "      <td>“Yesterday” is the most covered song in histor...</td>\n",
       "      <td>September 13, 1965</td>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191</td>\n",
       "      <td>the beatles</td>\n",
       "      <td>come together</td>\n",
       "      <td>\\nshoot me\\nshoot me\\nshoot me\\nshoot me\\n\\nhe...</td>\n",
       "      <td>“Come Together” is the opening track to Abbey ...</td>\n",
       "      <td>September 26, 1969</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "      <td>the beatles</td>\n",
       "      <td>hey jude</td>\n",
       "      <td>\\nhey jude dont make it bad\\ntake a sad song a...</td>\n",
       "      <td>Originally titled “Hey Jules,” named after Joh...</td>\n",
       "      <td>August 26, 1968</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       artist          title  \\\n",
       "0    189  the beatles      let it be   \n",
       "1    190  the beatles      yesterday   \n",
       "2    191  the beatles  come together   \n",
       "3    192  the beatles       hey jude   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  \\nwhen i find myself in times of trouble mothe...   \n",
       "1  \\nyesterday\\nall my troubles seemed so far awa...   \n",
       "2  \\nshoot me\\nshoot me\\nshoot me\\nshoot me\\n\\nhe...   \n",
       "3  \\nhey jude dont make it bad\\ntake a sad song a...   \n",
       "\n",
       "                                         description        release date  year  \n",
       "0  One of The Beatles' many iconic ballads, writt...         May 8, 1970  1970  \n",
       "1  “Yesterday” is the most covered song in histor...  September 13, 1965  1965  \n",
       "2  “Come Together” is the opening track to Abbey ...  September 26, 1969  1969  \n",
       "3  Originally titled “Hey Jules,” named after Joh...     August 26, 1968  1968  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['artist'] == 'the beatles'].reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86195017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "text = df['lyrics'][3].replace('\\n', ' ')\n",
    "\n",
    "\n",
    "encoding = t5_tokenizer.encode(\"\"\"summarize: \"\"\" + text, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c6f9f00-0efd-408b-9838-c18772980b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1181), dtype=int32, numpy=array([[21603,    10,     3, ..., 14312,    15,     1]], dtype=int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed60d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = t5.generate(encoding,\n",
    "                      num_beams=4, \n",
    "                      no_repeat_ngram_size=2,\n",
    "                      min_length=30,\n",
    "                      max_length=100,\n",
    "                      early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "150df5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 78), dtype=int32, numpy=\n",
       "array([[    0,     3, 13133,     3, 14312,    15,  2483,   143,    34,\n",
       "         1282,   240,     3,     9,  6819,  2324,   258,    25,    54,\n",
       "          456,    12,   143,     8,  2324,   394,    78,   752,    34,\n",
       "           91,    11,   752,   160,   139,    39,   842,     3,     5,\n",
       "           25,   214,    24,    34,    31,     7,   131,    25,     6,\n",
       "           25,   195,   103,     8,  2426,    25,   174,    19,    30,\n",
       "           39,  8173,     6,     3,    29,     9,     9,     3,     7,\n",
       "           29,    32,    32,    40,    11,     3,    32,   107, 17945,\n",
       "        17945,     3,    31, 10070, 17945,    31]], dtype=int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a893d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization = t5_tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d3d3001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey jude dont make it bad take a sad song then you can start to make the song better so let it out and let her into your heart . you know that it's just you, youll do the movement you need is on your shoulder, naa snool and oh yeah yeah 'yes yeah'\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "371d1035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"hey jude dont make it bad take a sad song then you can start to make the song better so let it out and let her into your heart . you know that it's just you, youll do the movement you need is on your shoulder, naa snool and oh yeah yeah 'yes yeah'\"]\n"
     ]
    }
   ],
   "source": [
    "print([t5_tokenizer.decode(g, skip_special_tokens=True, \n",
    "                           clean_up_tokenization_spaces=False) for g in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8b9c62b-5f7b-431f-9180-eb315b38ebf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hey jude dont make it bad take a sad song and make it better remember to let her into your heart then you can start to make it better  hey jude dont be afraid you were made to go out and get her the minute you let her under your skin then you begin to make it better  and anytime you feel the pain hey jude refrain dont carry the world upon your shoulders for well you know that its a fool who plays it cool by making his world a little colder na na na na na na na na na na  hey jude dont let me down you have found her now go and get her (let it out and let it in) remember (hey jude) to let her into your heart then you can start to make it better so let it out and let it in hey jude begin youre waiting for someone to perform with and dont you know that its just you hey jude youll do the movement you need is on your shoulder na na na na na na na na na yeah  hey jude dont make it bad take a sad song and make it better remember to let her under your skin then youll begin to make it (whoa fucking hell) better better better better better better oh  yeah yeah yeah yeah yeah yeah yeah naa na na na na na na na na na na hey jude naa na na na na na na na na na na hey jude naa na na na na na na na na na na hey jude naa na na na na na na na na na na hey jude (jude judy judy judy judy judy ow wow) naa na na na na na na (na na na) na na na na hey jude (jude jude jude jude jude) naa na na na na na na (yeah yeah yeah) na na na na hey jude (you know you can make jude jude youre not gonna break it) naa na (dont make it bad jude) na na na na na (take a sad song and make it better) na na na na hey jude hey jude hey jude wow naa na na na na na na na na na na hey jude naa na na na na na na na na na na hey jude jude jude jude jude jude jude naa na na na na na na na na na na hey jude naa na na na na na na na na na na hey jude (na na na na na na na na na na na na) naa na na na na na na na na na na hey jude naa na na na na na na na na na na hey jude naa na na na na na na (make it jude) na na na na hey jude (yeah yeah yeah yeah yeah yeah yeah) naa na na na na na na na na na na hey jude (go listen to ya ma ma ma ma ma ma ma ma) naa na na na na na na na na na na hey jude naa na na na na na na na na na na hey jude'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e691a0f6-c596-4904-8ff4-89220f7c56ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey jude dont make it bad take a sad song then you can start to make the song better so let it out and let her into your heart . you know that it's just you, youll do the movement you need is on your shoulder, naa snool and oh yeah yeah 'yes yeah'\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cb38ad-5576-4f21-b357-599b38eedced",
   "metadata": {},
   "source": [
    "## Evaluation Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4394394e-f388-4394-ab1e-2f46e01108c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/ccal0507/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bert_score -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4dffe7b-4307-44f4-b5ab-b8cbc3290e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.11'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bert_score\n",
    "bert_score.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf23d55a-21c8-4bd3-aa81-82fb5072de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c9ee03f-13f0-44d7-968d-8e57572f3e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' when i find myself in times of trouble mother mary comes to me speaking words of wisdom \"let it be\" and in my hour of darkness she is standing right in front of me speaking words of wisdom \"let it be\"  let it be let it be let it be let it be whisper words of wisdom let it be  and when the brokenhearted people living in the world agree there will be an answer let it be for though they may be parted there is still a chance that they will see there will be an answer let it be  let it be let it be let it be let it be yeah there will be an answer let it be let it be let it be let it be let it be whisper words of wisdom let it be  let it be let it be let it be yeah let it be whisper words of wisdom let it be and when the night is cloudy there is still a light that shines on me shine on til tomorrow let it be i wake up to the sound of music mother mary comes to me speaking words of wisdom \"let it be\"  let it be let it be let it be yeah let it be oh there will be an answer let it be let it be let it be let it be yeah let it be oh there will be an answer let it be let it be let it be let it be yeah let it be whisper words of wisdom let it be'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22cf144c-79ec-483d-85cd-dce121990878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mother mary comes to me speaking words of wisdom \"let it be\" let the answer be let it go yeah . when the brokenhearted people may be parted there will be a answer for if they will see there is still an answer letting it get letit be whisper words oh i wake up to the sound of music mother she is standing right in front of me talking words about wisdom \\'let the be\\''"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c3f7fef-e0bc-4018-bfab-56da5a6915b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Different number of candidates and references",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-10874a7d23b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/bert_score/score.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[1;32m     78\u001b[0m                   \u001b[0mthe\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mscore\u001b[0m \u001b[0mamong\u001b[0m \u001b[0mall\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcands\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Different number of candidates and references\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Either lang or model_type should be specified\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Different number of candidates and references"
     ]
    }
   ],
   "source": [
    "score(summarization, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80281874-2ff2-4a8d-84d1-47f633ea3cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed10914e-78d6-494d-bee9-79e1a0aa33d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c19e0-a4ef-4ecd-b17f-0dcb928332de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e1819-672b-448d-a5a4-06b35c9ff540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eee238-e791-40c6-9fbf-fa94b741578c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cee4b7-d405-41fc-95e4-f9e7147aa97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd03d5c9-f64d-4dd1-9814-ee9597c144c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-extractive-summarizer\n",
      "  Downloading bert_extractive_summarizer-0.10.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: spacy in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from bert-extractive-summarizer) (3.2.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from bert-extractive-summarizer) (0.24.1)\n",
      "Requirement already satisfied: transformers in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from bert-extractive-summarizer) (4.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from scikit-learn->bert-extractive-summarizer) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from scikit-learn->bert-extractive-summarizer) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from scikit-learn->bert-extractive-summarizer) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from scikit-learn->bert-extractive-summarizer) (1.22.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (8.0.15)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (1.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (1.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (2.27.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (0.7.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (21.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (2.0.7)\n",
      "Requirement already satisfied: setuptools in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (52.0.0.post20210125)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (3.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (4.63.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (0.4.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (2.11.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (0.6.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (2.4.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer) (1.8.2)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from transformers->bert-extractive-summarizer) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from transformers->bert-extractive-summarizer) (2022.3.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from transformers->bert-extractive-summarizer) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from transformers->bert-extractive-summarizer) (6.0)\n",
      "Requirement already satisfied: filelock in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from transformers->bert-extractive-summarizer) (3.6.0)\n",
      "Requirement already satisfied: sacremoses in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from transformers->bert-extractive-summarizer) (0.0.47)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers->bert-extractive-summarizer) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy->bert-extractive-summarizer) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy->bert-extractive-summarizer) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.0.12)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy->bert-extractive-summarizer) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from jinja2->spacy->bert-extractive-summarizer) (1.1.1)\n",
      "Requirement already satisfied: six in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers->bert-extractive-summarizer) (1.16.0)\n",
      "Installing collected packages: bert-extractive-summarizer\n",
      "Successfully installed bert-extractive-summarizer-0.10.1\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/ccal0507/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers==2.2.0\n",
    "!pip install bert-extractive-summarizer\n",
    "#!pip install spacy==2.0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ead77c-a45f-47e2-8f08-ebd2619d15e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer import Summarizer,TransformerSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf6f880c-987b-4c88-8a3d-d8e3c995380a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of The Beatles' many iconic ballads, written by McCartney. The level of repetition in the lyrics suggests this song was written quickly and through emotional inspiration — similar patterns can be seen in songs like “Hey Jude”.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7d7b363-c92f-4d3d-abd7-2a06d04cd045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f2db7f36ee0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f2db7f36ee0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f2db7f36ee0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f2db7f36ee0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f2db7f36ee0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f2db74fd1f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f2db74fd1f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f2db74fd1f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f2db74fd1f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f2db74fd1f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f2db74fd1f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/ccal0507/anaconda3/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "bert_model = Summarizer()\n",
    "bert_summary = ''.join(bert_model(text, min_length=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a41a8fe-1215-4116-8d64-68a1d8d90212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of The Beatles' many iconic ballads, written by McCartney. The level of repetition in the lyrics suggests this song was written quickly and through emotional inspiration — similar patterns can be seen in songs like “Hey Jude”.\n"
     ]
    }
   ],
   "source": [
    "print(bert_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0802adc8-b545-4c5e-908c-0ca1f4d19efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of The Beatles' many iconic ballads, written by McCartney. The level of repetition in the lyrics suggests this song was written quickly and through emotional inspiration — similar patterns can be seen in songs like “Hey Jude”.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9074ede-a734-43ec-bc4e-807440f52c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ded60-0cf2-44de-a6d5-38e468756170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "963f83ea",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bf9a784-c1f4-4b2b-bd19-8dea2d42302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_transformers\n",
      "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
      "     |████████████████████████████████| 176 kB 7.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from pytorch_transformers) (2.27.1)\n",
      "Requirement already satisfied: sacremoses in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from pytorch_transformers) (0.0.47)\n",
      "Requirement already satisfied: tqdm in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from pytorch_transformers) (4.63.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from pytorch_transformers) (1.11.0)\n",
      "Requirement already satisfied: numpy in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from pytorch_transformers) (1.22.2)\n",
      "Requirement already satisfied: sentencepiece in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from pytorch_transformers) (0.1.96)\n",
      "Requirement already satisfied: regex in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from pytorch_transformers) (2022.3.2)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.21.27-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 46.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from torch>=1.0.0->pytorch_transformers) (4.1.1)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
      "     |████████████████████████████████| 79 kB 966 kB/s             \n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
      "Collecting botocore<1.25.0,>=1.24.27\n",
      "  Downloading botocore-1.24.27-py3-none-any.whl (8.6 MB)\n",
      "     |████████████████████████████████| 8.6 MB 48.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests->pytorch_transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests->pytorch_transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests->pytorch_transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from requests->pytorch_transformers) (1.26.8)\n",
      "Requirement already satisfied: six in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from sacremoses->pytorch_transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from sacremoses->pytorch_transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from sacremoses->pytorch_transformers) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ccal0507/anaconda3/lib/python3.8/site-packages (from botocore<1.25.0,>=1.24.27->boto3->pytorch_transformers) (2.8.1)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-transformers\n",
      "Successfully installed boto3-1.21.27 botocore-1.24.27 jmespath-1.0.0 pytorch-transformers-1.2.0 s3transfer-0.5.2\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/ccal0507/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bbdb3e0-e96b-43a4-ac7a-73713282a171",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e558a97b1322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxavier_uniform_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformerDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtTransformerEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_transformers import BertModel, BertConfig\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "from models.decoder import TransformerDecoder\n",
    "from models.encoder import Classifier, ExtTransformerEncoder\n",
    "from models.optimizers import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2186c47c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-abfad0311fd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mBert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlarge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinetune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlarge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-large-uncased'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Bert(nn.Module):\n",
    "    def __init__(self, large, temp_dir, finetune=False):\n",
    "        super(Bert, self).__init__()\n",
    "        if(large):\n",
    "            self.model = BertModel.from_pretrained('bert-large-uncased', cache_dir=temp_dir)\n",
    "        else:\n",
    "            self.model = BertModel.from_pretrained('bert-base-uncased', cache_dir=temp_dir)\n",
    "\n",
    "        self.finetune = finetune\n",
    "\n",
    "    def forward(self, x, segs, mask):\n",
    "        if(self.finetune):\n",
    "            top_vec, _ = self.model(x, segs, attention_mask=mask)\n",
    "        else:\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                top_vec, _ = self.model(x, segs, attention_mask=mask)\n",
    "        return top_vec\n",
    "\n",
    "\n",
    "class ExtSummarizer(nn.Module):\n",
    "    def __init__(self, args, device, checkpoint):\n",
    "        super(ExtSummarizer, self).__init__()\n",
    "        self.args = args\n",
    "        self.device = device\n",
    "        self.bert = Bert(args.large, args.temp_dir, args.finetune_bert)\n",
    "\n",
    "        self.ext_layer = ExtTransformerEncoder(self.bert.model.config.hidden_size, args.ext_ff_size, args.ext_heads,\n",
    "                                               args.ext_dropout, args.ext_layers)\n",
    "        if (args.encoder == 'baseline'):\n",
    "            bert_config = BertConfig(self.bert.model.config.vocab_size, hidden_size=args.ext_hidden_size,\n",
    "                                     num_hidden_layers=args.ext_layers, num_attention_heads=args.ext_heads, intermediate_size=args.ext_ff_size)\n",
    "            self.bert.model = BertModel(bert_config)\n",
    "            self.ext_layer = Classifier(self.bert.model.config.hidden_size)\n",
    "\n",
    "        if(args.max_pos>512):\n",
    "            my_pos_embeddings = nn.Embedding(args.max_pos, self.bert.model.config.hidden_size)\n",
    "            my_pos_embeddings.weight.data[:512] = self.bert.model.embeddings.position_embeddings.weight.data\n",
    "            my_pos_embeddings.weight.data[512:] = self.bert.model.embeddings.position_embeddings.weight.data[-1][None,:].repeat(args.max_pos-512,1)\n",
    "            self.bert.model.embeddings.position_embeddings = my_pos_embeddings\n",
    "\n",
    "\n",
    "        if checkpoint is not None:\n",
    "            self.load_state_dict(checkpoint['model'], strict=True)\n",
    "        else:\n",
    "            if args.param_init != 0.0:\n",
    "                for p in self.ext_layer.parameters():\n",
    "                    p.data.uniform_(-args.param_init, args.param_init)\n",
    "            if args.param_init_glorot:\n",
    "                for p in self.ext_layer.parameters():\n",
    "                    if p.dim() > 1:\n",
    "                        xavier_uniform_(p)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, src, segs, clss, mask_src, mask_cls):\n",
    "        top_vec = self.bert(src, segs, mask_src)\n",
    "        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss]\n",
    "        sents_vec = sents_vec * mask_cls[:, :, None].float()\n",
    "        sent_scores = self.ext_layer(sents_vec, mask_cls).squeeze(-1)\n",
    "        return sent_scores, mask_cls\n",
    "\n",
    "\n",
    "class AbsSummarizer(nn.Module):\n",
    "    def __init__(self, args, device, checkpoint=None, bert_from_extractive=None):\n",
    "        super(AbsSummarizer, self).__init__()\n",
    "        self.args = args\n",
    "        self.device = device\n",
    "        self.bert = Bert(args.large, args.temp_dir, args.finetune_bert)\n",
    "\n",
    "        if bert_from_extractive is not None:\n",
    "            self.bert.model.load_state_dict(\n",
    "                dict([(n[11:], p) for n, p in bert_from_extractive.items() if n.startswith('bert.model')]), strict=True)\n",
    "\n",
    "        if (args.encoder == 'baseline'):\n",
    "            bert_config = BertConfig(self.bert.model.config.vocab_size, hidden_size=args.enc_hidden_size,\n",
    "                                     num_hidden_layers=args.enc_layers, num_attention_heads=8,\n",
    "                                     intermediate_size=args.enc_ff_size,\n",
    "                                     hidden_dropout_prob=args.enc_dropout,\n",
    "                                     attention_probs_dropout_prob=args.enc_dropout)\n",
    "            self.bert.model = BertModel(bert_config)\n",
    "\n",
    "        if(args.max_pos>512):\n",
    "            my_pos_embeddings = nn.Embedding(args.max_pos, self.bert.model.config.hidden_size)\n",
    "            my_pos_embeddings.weight.data[:512] = self.bert.model.embeddings.position_embeddings.weight.data\n",
    "            my_pos_embeddings.weight.data[512:] = self.bert.model.embeddings.position_embeddings.weight.data[-1][None,:].repeat(args.max_pos-512,1)\n",
    "            self.bert.model.embeddings.position_embeddings = my_pos_embeddings\n",
    "        self.vocab_size = self.bert.model.config.vocab_size\n",
    "        tgt_embeddings = nn.Embedding(self.vocab_size, self.bert.model.config.hidden_size, padding_idx=0)\n",
    "        if (self.args.share_emb):\n",
    "            tgt_embeddings.weight = copy.deepcopy(self.bert.model.embeddings.word_embeddings.weight)\n",
    "\n",
    "        self.decoder = TransformerDecoder(\n",
    "            self.args.dec_layers,\n",
    "            self.args.dec_hidden_size, heads=self.args.dec_heads,\n",
    "            d_ff=self.args.dec_ff_size, dropout=self.args.dec_dropout, embeddings=tgt_embeddings)\n",
    "\n",
    "        self.generator = get_generator(self.vocab_size, self.args.dec_hidden_size, device)\n",
    "        self.generator[0].weight = self.decoder.embeddings.weight\n",
    "\n",
    "\n",
    "        if checkpoint is not None:\n",
    "            self.load_state_dict(checkpoint['model'], strict=True)\n",
    "        else:\n",
    "            for module in self.decoder.modules():\n",
    "                if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "                    module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                elif isinstance(module, nn.LayerNorm):\n",
    "                    module.bias.data.zero_()\n",
    "                    module.weight.data.fill_(1.0)\n",
    "                if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            for p in self.generator.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    xavier_uniform_(p)\n",
    "                else:\n",
    "                    p.data.zero_()\n",
    "            if(args.use_bert_emb):\n",
    "                tgt_embeddings = nn.Embedding(self.vocab_size, self.bert.model.config.hidden_size, padding_idx=0)\n",
    "                tgt_embeddings.weight = copy.deepcopy(self.bert.model.embeddings.word_embeddings.weight)\n",
    "                self.decoder.embeddings = tgt_embeddings\n",
    "                self.generator[0].weight = self.decoder.embeddings.weight\n",
    "\n",
    "        self.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
