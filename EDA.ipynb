{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b58f196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ccal0507/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e86796",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770063fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lyrics.csv')\n",
    "# Removing any songs without lyrics \n",
    "df = df[~(pd.isna(df['lyrics']) | pd.isna(df['release date']))]\n",
    "df.head()\n",
    "\n",
    "# Defining a dataset with nonempty descriptions for *maybe* future use\n",
    "data = df.query(\"description != '?'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9662926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 373 entries, 0 to 384\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   artist        373 non-null    object\n",
      " 1   title         373 non-null    object\n",
      " 2   lyrics        373 non-null    object\n",
      " 3   description   373 non-null    object\n",
      " 4   release date  373 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 17.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Original data description \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222a73f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 313 entries, 0 to 384\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   artist        313 non-null    object\n",
      " 1   title         313 non-null    object\n",
      " 2   lyrics        313 non-null    object\n",
      " 3   description   313 non-null    object\n",
      " 4   release date  313 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 14.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Nonempty description data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a94951",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "\n",
    "### Cleaning `lyrics`, `artist`, and `title`  \n",
    "In this section we are removing any unecessary text found in the lyrics column. In addition, we are lowercasing all other textual columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9ff62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics(test_str):\n",
    "    \n",
    "    test_str = str(test_str)\n",
    "    # 0) Removing apostrophes for tokenization purposes\n",
    "    test_str = test_str.lower().replace(\"'\", \"\")\n",
    "    \n",
    "    # 1) Removing unecessary textual data \n",
    "    res = re.search(r'lyrics' , test_str)\n",
    "    emb_res = re.search(r'\\d*embed$', test_str)\n",
    "\n",
    "    test_str = test_str[res.end():emb_res.start()]\n",
    "\n",
    "    # 2) Removing any punctuation (except parantheses)\n",
    "    test_str = re.sub(r'[.,\\-?:!;]', '', test_str)\n",
    "\n",
    "    return test_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54bd3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lyrics'] = df['lyrics'].apply(clean_lyrics)\n",
    "df['artist'] = df['artist'].str.lower()\n",
    "df['title'] = df['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5f55f88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>description</th>\n",
       "      <th>release date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>hit the road jack</td>\n",
       "      <td>\\nhit the road jack and doncha come back\\nno m...</td>\n",
       "      <td>This tongue and cheek verbal duel of a couple ...</td>\n",
       "      <td>August 1961</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>georgia on my mind</td>\n",
       "      <td>\\ngeorgia\\ngeorgia\\nthe whole day through\\n(th...</td>\n",
       "      <td>Written by Hoagy Carmichael and Stuart Gorrell...</td>\n",
       "      <td>September 1960</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist               title  \\\n",
       "0  ray charles   hit the road jack   \n",
       "1  ray charles  georgia on my mind   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  \\nhit the road jack and doncha come back\\nno m...   \n",
       "1  \\ngeorgia\\ngeorgia\\nthe whole day through\\n(th...   \n",
       "\n",
       "                                         description    release date  year  \n",
       "0  This tongue and cheek verbal duel of a couple ...     August 1961  1961  \n",
       "1  Written by Hoagy Carmichael and Stuart Gorrell...  September 1960  1960  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4aca256c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>description</th>\n",
       "      <th>release date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>hit the road jack</td>\n",
       "      <td>\\nhit the road jack and doncha come back\\nno m...</td>\n",
       "      <td>This tongue and cheek verbal duel of a couple ...</td>\n",
       "      <td>August 1961</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ray charles</td>\n",
       "      <td>georgia on my mind</td>\n",
       "      <td>\\ngeorgia\\ngeorgia\\nthe whole day through\\n(th...</td>\n",
       "      <td>Written by Hoagy Carmichael and Stuart Gorrell...</td>\n",
       "      <td>September 1960</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist               title  \\\n",
       "0  ray charles   hit the road jack   \n",
       "1  ray charles  georgia on my mind   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  \\nhit the road jack and doncha come back\\nno m...   \n",
       "1  \\ngeorgia\\ngeorgia\\nthe whole day through\\n(th...   \n",
       "\n",
       "                                         description    release date  year  \n",
       "0  This tongue and cheek verbal duel of a couple ...     August 1961  1961  \n",
       "1  Written by Hoagy Carmichael and Stuart Gorrell...  September 1960  1960  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'] = pd.to_datetime(df['release date']).dt.year\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c427e4",
   "metadata": {},
   "source": [
    "### Building our Feature Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46c4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb9014a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_df = df[df['artist'] == 'the notorious b.i.g.']\n",
    "corpus = list(curr_df['lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65651c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14f2c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_sequences, total_words = get_sequence_of_tokens(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e3367a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "816"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e93eac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = np_utils.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dcd5fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad34fc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d675c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(100))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_sequence_len, total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f314ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "88/88 - 62s - loss: 6.2524\n",
      "Epoch 2/10\n",
      "88/88 - 59s - loss: 5.8697\n",
      "Epoch 3/10\n",
      "88/88 - 60s - loss: 5.8151\n",
      "Epoch 4/10\n",
      "88/88 - 61s - loss: 5.7586\n",
      "Epoch 5/10\n",
      "88/88 - 60s - loss: 5.6797\n",
      "Epoch 6/10\n",
      "88/88 - 60s - loss: 5.6311\n",
      "Epoch 7/10\n",
      "88/88 - 61s - loss: 5.4989\n",
      "Epoch 8/10\n",
      "88/88 - 62s - loss: 5.4054\n",
      "Epoch 9/10\n",
      "88/88 - 61s - loss: 5.3115\n",
      "Epoch 10/10\n",
      "88/88 - 59s - loss: 5.2034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f21c83e5100>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48664130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        #predicted = model.predict_classes(token_list, verbose=0)\n",
    "        \n",
    "        predict_x=model.predict(token_list) \n",
    "        classes_x=np.argmax(predict_x,axis=1)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == classes_x:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word        \n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b63d6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Want I The Fuckin To My Fuckin To To My Back To My Back To My Fuckin To My Back To\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"You want\", 20, model, max_sequence_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adfccb4",
   "metadata": {},
   "source": [
    "## Text Summarization Baseline Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58828233",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a3afecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import spacy.lang.en.stop_words as STOP_WORDS\n",
    "from string import punctuation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c78eff6",
   "metadata": {},
   "source": [
    "Will first attempt to summarize one song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7f2bf128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhit the road jack and doncha come back\\nno more no more no more no more\\nhit the road jack and doncha come back no more\\nwhatd you say\\nhit the road jack and doncha come back\\nno more no more no more no more\\nhit the road jack and doncha come back no more\\nold woman old woman oh you treat me so mean\\nyoure the meanest old woman that ive ever seen\\ni guess if you say so\\nill have to pack my things and go (thats right)\\nhit the road jack and doncha come back\\nno more no more no more no more\\nhit the road jack and doncha come back no more\\nwhatd you say\\nhit the road jack and doncha come back\\nno more no more no more no more\\nhit the road jack and doncha come back no more\\nnow baby listen baby dont you treat me this way\\ncause ill be back on my feet some day\\ndont care if you do cause its understood\\nyou aint got no money you just a no good\\nwell i guess if you say so\\nill have to pack my things and go (thats right)\\nhit the road jack and doncha come back\\nno more no more no more no more\\nhit the road jack and doncha come back no more\\nwhatd you say\\nhit the road jack and doncha come back\\nno more no more no more no more\\nhit the road jack and doncha come back no more\\nwell (doncha come back no more)\\nuh whatd you say (doncha come back no more)\\ni didnt understand you (doncha come back no more)\\nyou cant mean that (doncha come back no more)\\noh now baby please (doncha come back no more)\\nwhat youre trying to do to me (doncha come back no more)'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['lyrics'][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8dc42f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(STOP_WORDS.STOP_WORDS)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fb8ac75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "95ca5813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'hit', 'the', 'road', 'jack', 'and', 'doncha', 'come', 'back', '\\n', 'no', 'more', 'no', 'more', 'no', 'more', 'no', 'more', '\\n', 'hit', 'the', 'road', 'jack', 'and', 'doncha', 'come', 'back', 'no', 'more', '\\n', 'what', 'd', 'you', 'say', '\\n', 'hit', 'the', 'road', 'jack', 'and', 'doncha', 'come', 'back', '\\n', 'no', 'more', 'no', 'more', 'no', 'more', 'no', 'more', '\\n', 'hit', 'the', 'road', 'jack', 'and', 'doncha', 'come', 'back', 'no', 'more', '\\n', 'old', 'woman', 'old', 'woman', 'oh', 'you', 'treat', 'me', 'so', 'mean', '\\n', 'you', 're', 'the', 'meanest', 'old', 'woman', 'that', 'i', 've', 'ever', 'seen', '\\n', 'i', 'guess', 'if', 'you', 'say', 'so', '\\n', 'ill', 'have', 'to', 'pack', 'my', 'things', 'and', 'go', '(', 'that', 's', 'right', ')', '\\n', 'hit', 'the', 'road', 'jack', 'and', 'doncha', 'come', 'back', '\\n', 'no', 'more', 'no', 'more', 'no', 'more', 'no', 'more', '\\n', 'hit', 'the', 'road', 'jack', 'and', 'doncha', 'come', 'back', 'no', 'more', '\\n', 'what', 'd', 'you', 'say', '\\n', 'hit', 'the', 'road', 'jack', 'and', 'doncha', 'come', 'back', '\\n', 'no', 'more', 'no', 'more', 'no', 'more', 'no', 'more', '\\n', 'hit', 'the', 'road', 'jack', 'and', 'doncha', 'come', 'back', 'no', 'more', '\\n', 'now', 'baby', 'listen', 'baby', 'do', 'nt', 'you', 'treat', 'me', 'this', 'way', '\\n', 'cause', 'ill', 'be', 'back', 'on', 'my', 'feet', 'some', 'day', '\\n', 'do', 'nt', 'care', 'if', 'you', 'do', 'cause', 'its', 'understood', '\\n', 'you', 'ai', 'nt', 'got', 'no', 'money', 'you', 'just', 'a', 'no', 'good', '\\n', 'well', 'i', 'guess', 'if', 'you', 'say', 'so', '\\n', 'ill', 'have', 'to', 'pack', 'my', 'things', 'and', 'go', '(', 'that', 's', 'right', ')', '\\n', 'hit', 'the', 'road', 'jack', 'and', 'doncha', 'come', 'back', '\\n', 'no', 'more', 'no', 'more', 'no', 'more', 'no', 'more', '\\n', 'hit', 'the', 'road', 'jack', 'and', 'doncha', 'come', 'back', 'no', 'more', '\\n', 'what', 'd', 'you', 'say', '\\n', 'hit', 'the', 'road', 'jack', 'and', 'doncha', 'come', 'back', '\\n', 'no', 'more', 'no', 'more', 'no', 'more', 'no', 'more', '\\n', 'hit', 'the', 'road', 'jack', 'and', 'doncha', 'come', 'back', 'no', 'more', '\\n', 'well', '(', 'doncha', 'come', 'back', 'no', 'more', ')', '\\n', 'uh', 'what', 'd', 'you', 'say', '(', 'doncha', 'come', 'back', 'no', 'more', ')', '\\n', 'i', 'did', 'nt', 'understand', 'you', '(', 'doncha', 'come', 'back', 'no', 'more', ')', '\\n', 'you', 'ca', 'nt', 'mean', 'that', '(', 'doncha', 'come', 'back', 'no', 'more', ')', '\\n', 'oh', 'now', 'baby', 'please', '(', 'doncha', 'come', 'back', 'no', 'more', ')', '\\n', 'what', 'you', 're', 'trying', 'to', 'do', 'to', 'me', '(', 'doncha', 'come', 'back', 'no', 'more', ')']\n"
     ]
    }
   ],
   "source": [
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "50885ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding how many times each token appears in the song \n",
    "\n",
    "all_frequencies = {}\n",
    "word_frequencies = {}\n",
    "\n",
    "for word in doc:\n",
    "    if word.text not in punctuation and word.text != '\\n' and word.text not in stopwords: \n",
    "        if word.text not in word_frequencies.keys():\n",
    "            word_frequencies[word.text] = 1\n",
    "        else:\n",
    "            word_frequencies[word.text] += 1\n",
    "    if word.text not in all_frequencies.keys():\n",
    "        all_frequencies[word.text] = 1\n",
    "    else:\n",
    "        all_frequencies[word.text] += 1\n",
    "\n",
    "# Ideas: Deal with \\n and () and stopwords differently --> they mean something else in lyrics \n",
    "    #    and encode their positional index to encode chorus vs. verse vs. bridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "baf137f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit': 12, 'road': 12, 'jack': 12, 'doncha': 18, 'come': 18, 'd': 4, 'old': 3, 'woman': 3, 'oh': 2, 'treat': 2, 'mean': 2, 'meanest': 1, 've': 1, 'seen': 1, 'guess': 2, 'ill': 3, 'pack': 2, 'things': 2, 's': 2, 'right': 2, 'baby': 3, 'listen': 1, 'nt': 5, 'way': 1, 'cause': 2, 'feet': 1, 'day': 1, 'care': 1, 'understood': 1, 'ai': 1, 'got': 1, 'money': 1, 'good': 1, 'uh': 1, 'understand': 1, 'trying': 1}\n",
      "{'\\n': 37, 'hit': 12, 'the': 13, 'road': 12, 'jack': 12, 'and': 14, 'doncha': 18, 'come': 18, 'back': 19, 'no': 38, 'more': 36, 'what': 5, 'd': 4, 'you': 15, 'say': 6, 'old': 3, 'woman': 3, 'oh': 2, 'treat': 2, 'me': 3, 'so': 3, 'mean': 2, 're': 2, 'meanest': 1, 'that': 4, 'i': 4, 've': 1, 'ever': 1, 'seen': 1, 'guess': 2, 'if': 3, 'ill': 3, 'have': 2, 'to': 4, 'pack': 2, 'my': 3, 'things': 2, 'go': 2, '(': 8, 's': 2, 'right': 2, ')': 8, 'now': 2, 'baby': 3, 'listen': 1, 'do': 4, 'nt': 5, 'this': 1, 'way': 1, 'cause': 2, 'be': 1, 'on': 1, 'feet': 1, 'some': 1, 'day': 1, 'care': 1, 'its': 1, 'understood': 1, 'ai': 1, 'got': 1, 'money': 1, 'just': 1, 'a': 1, 'good': 1, 'well': 2, 'uh': 1, 'did': 1, 'understand': 1, 'ca': 1, 'please': 1, 'trying': 1}\n"
     ]
    }
   ],
   "source": [
    "print(word_frequencies)\n",
    "print(all_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4c01675a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 18)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_all_frequency = max(all_frequencies.values())\n",
    "max_word_frequency = max(word_frequencies.values())\n",
    "\n",
    "max_all_frequency, max_word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "43e6314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word]/max_word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "81d81928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit': 0.6666666666666666, 'road': 0.6666666666666666, 'jack': 0.6666666666666666, 'doncha': 1.0, 'come': 1.0, 'd': 0.2222222222222222, 'old': 0.16666666666666666, 'woman': 0.16666666666666666, 'oh': 0.1111111111111111, 'treat': 0.1111111111111111, 'mean': 0.1111111111111111, 'meanest': 0.05555555555555555, 've': 0.05555555555555555, 'seen': 0.05555555555555555, 'guess': 0.1111111111111111, 'ill': 0.16666666666666666, 'pack': 0.1111111111111111, 'things': 0.1111111111111111, 's': 0.1111111111111111, 'right': 0.1111111111111111, 'baby': 0.16666666666666666, 'listen': 0.05555555555555555, 'nt': 0.2777777777777778, 'way': 0.05555555555555555, 'cause': 0.1111111111111111, 'feet': 0.05555555555555555, 'day': 0.05555555555555555, 'care': 0.05555555555555555, 'understood': 0.05555555555555555, 'ai': 0.05555555555555555, 'got': 0.05555555555555555, 'money': 0.05555555555555555, 'good': 0.05555555555555555, 'uh': 0.05555555555555555, 'understand': 0.05555555555555555, 'trying': 0.05555555555555555}\n"
     ]
    }
   ],
   "source": [
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "54836999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " hit the road jack and doncha come back\n",
       " no more no more no more no more\n",
       " hit the road jack and doncha come back no more\n",
       " whatd you say\n",
       " hit the road jack and doncha come back\n",
       " no more no more no more no more\n",
       " hit the road jack and doncha come back no more\n",
       " old woman old woman,\n",
       " oh you treat me so mean\n",
       " youre the meanest old woman that ive ever seen,\n",
       " i guess if you say so\n",
       " ill have to pack my things and go (thats right),\n",
       " \n",
       " hit the road jack and doncha come back\n",
       " no more no more no more no more\n",
       " hit the road jack and doncha come back no more\n",
       " whatd you say\n",
       " hit the road jack and doncha come back\n",
       " no more no more no more no more\n",
       " hit the road jack and doncha come back no more\n",
       " now baby listen baby dont you treat me this way\n",
       " cause ill be back on my feet some day\n",
       " dont care if you do cause its understood\n",
       " you aint got no money you just a no good,\n",
       " well i guess if you say so\n",
       " ill have to pack my things and go (thats right),\n",
       " \n",
       " hit the road jack and doncha come back\n",
       " no more no more no more no more\n",
       " hit the road jack and doncha come back no more\n",
       " whatd you say\n",
       " hit the road jack and doncha come back\n",
       " no more no more no more no more\n",
       " hit the road jack and doncha come back no more,\n",
       " well (doncha come back no more)\n",
       " uh whatd you say (doncha come back no more)\n",
       " i didnt understand you (doncha come back no more),\n",
       " \n",
       " you cant mean that (doncha come back no more),\n",
       " \n",
       " oh now baby please (doncha come back no more)\n",
       " what youre trying to do to me (doncha come back no more)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens = [sent for sent in doc.sents]\n",
    "sentence_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a3e03b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores = {}\n",
    "\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent: \n",
    "        if word.text.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.text.lower()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "38fe09e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "hit the road jack and doncha come back\n",
      "no more no more no more no more\n",
      "hit the road jack and doncha come back no more\n",
      "whatd you say\n",
      "hit the road jack and doncha come back\n",
      "no more no more no more no more\n",
      "hit the road jack and doncha come back no more\n",
      "old woman old woman: 16.88888888888889, oh you treat me so mean\n",
      "youre the meanest old woman that ive ever seen\n",
      ": 0.8333333333333333, i guess if you say so\n",
      "ill have to pack my things and go (thats right): 0.7222222222222223, \n",
      "hit the road jack and doncha come back\n",
      "no more no more no more no more\n",
      "hit the road jack and doncha come back no more\n",
      "whatd you say\n",
      "hit the road jack and doncha come back\n",
      "no more no more no more no more\n",
      "hit the road jack and doncha come back no more\n",
      "now baby listen baby dont you treat me this way\n",
      "cause ill be back on my feet some day\n",
      "dont care if you do cause its understood\n",
      "you aint got no money you just a no good\n",
      ": 18.44444444444446, well i guess if you say so\n",
      "ill have to pack my things and go (thats right): 0.7222222222222223, \n",
      "hit the road jack and doncha come back\n",
      "no more no more no more no more\n",
      "hit the road jack and doncha come back no more\n",
      "whatd you say\n",
      "hit the road jack and doncha come back\n",
      "no more no more no more no more\n",
      "hit the road jack and doncha come back no more\n",
      ": 16.222222222222218, well (doncha come back no more)\n",
      "uh whatd you say (doncha come back no more)\n",
      "i didnt understand you (doncha come back no more): 6.611111111111111, \n",
      "you cant mean that (doncha come back no more): 2.388888888888889, \n",
      "oh now baby please (doncha come back no more)\n",
      "what youre trying to do to me (doncha come back no more): 4.333333333333333}\n"
     ]
    }
   ],
   "source": [
    "print(sentence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd38fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2e71bf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_length = int(len(sentence_tokens) * 0.3)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "436a99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = nlargest(select_length, sentence_scores, \n",
    "                   key = sentence_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "60d1d8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " hit the road jack and doncha come back\n",
       " no more no more no more no more\n",
       " hit the road jack and doncha come back no more\n",
       " whatd you say\n",
       " hit the road jack and doncha come back\n",
       " no more no more no more no more\n",
       " hit the road jack and doncha come back no more\n",
       " now baby listen baby dont you treat me this way\n",
       " cause ill be back on my feet some day\n",
       " dont care if you do cause its understood\n",
       " you aint got no money you just a no good,\n",
       " \n",
       " hit the road jack and doncha come back\n",
       " no more no more no more no more\n",
       " hit the road jack and doncha come back no more\n",
       " whatd you say\n",
       " hit the road jack and doncha come back\n",
       " no more no more no more no more\n",
       " hit the road jack and doncha come back no more\n",
       " old woman old woman]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05620f",
   "metadata": {},
   "source": [
    "Not very good and it will do worse with rap songs. Will have to figure out a way to remove explicit lyrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
